{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project 2: Photo Filters",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project 2: Photo Filters\n",
        "\n",
        "⚠️   **Duplicate this project before you start working on it, using `File > Save a copy in drive`.**\n",
        "\n",
        "In this project, you'll be applying filters to photos, like inversion, flipping, and grayscale- and you'll be writing all those filters yourself!\n",
        "\n",
        "A photo can be represented in computer memory as a nested list of pixels, so playing with photos is a great way to practice your newfound list knowledge. And, of course, in order to process a nested list, you'll need nested loops, so photo filters involve lots of nested loops. You'll also learn a bit about representing pixels in the RGB color space, if you've never played with RGB before."
      ],
      "metadata": {
        "id": "GSVTpC0lxIBm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From Picture to Pixels\n",
        "\n",
        "In this first step, the program finds a picture on the web, loads the picture file into Python, and converts that file into an array of pixels. That requires the use of several external libraries, so we've written all the pixel loading code for you.\n",
        "\n",
        "### ✏︎ For you to do:\n",
        "\n",
        "* Read through the code and the comments. You don't need to understand every line of code, but you should roughly understand what `get_image_pixels` and `render_pixels` can do.\n",
        "* Find a picture on the web. A smaller picture is actually better at first, since your program will run faster and you can iterate more quickly. Even a 200x300 pixture has 60,000 pixels!\n",
        "* Replace the current value of the `url` variable with the address to your picture. That URL _must_ be to an image file (ending with an extension like .jpg/.png/.gif/.webp), not to a webpage displaying the image."
      ],
      "metadata": {
        "id": "TgEMMzH9-lYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import some standard libraries\n",
        "import doctest\n",
        "import copy\n",
        "\n",
        "# Import external libraries\n",
        "import numpy\n",
        "import cv2\n",
        "from skimage import io\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def get_image_pixels(image_url):\n",
        "  \"\"\" Returns a nested list of the pixels for the image located at image_url\"\"\"\n",
        "  # Fetch the image\n",
        "  image = io.imread(image_url)\n",
        "  # Convert the Blue-Green-Red representation to Red-Green-Blue representation\n",
        "  image2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  # Get an array of pixels representing the image\n",
        "  pixel_data = numpy.asarray(image2).tolist()\n",
        "  for row in pixel_data:\n",
        "    for pixel in row:\n",
        "      pixel[0], pixel[2] = pixel[2], pixel[0]\n",
        "  return pixel_data\n",
        "\n",
        "def render_pixels(pixel_data):\n",
        "  \"\"\" Displays the image represented by pixel_data\"\"\"\n",
        "  # Write the pixel_data to a local image file\n",
        "  transformed_data = copy.deepcopy(pixel_data)\n",
        "  for row in transformed_data:\n",
        "    for pixel in row:\n",
        "      pixel[0], pixel[2] = pixel[2], pixel[0]\n",
        "  cv2.imwrite('rendered.jpg', numpy.array(transformed_data))\n",
        "  # Display that image file in the notebook\n",
        "  cv2_imshow(cv2.imread(\"rendered.jpg\"))\n",
        "\n",
        "# Use the functions above to fetch pixel data and render the original data\n",
        "url = 'https://www2.eecs.berkeley.edu/Faculty/Photos/Homepages/pamelafox.jpg'\n",
        "pixel_data = get_image_pixels(url)\n",
        "render_pixels(pixel_data)"
      ],
      "metadata": {
        "id": "zaTru8LcAG_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring the Pixel Data\n",
        "\n",
        "Before you start messing with the pixels list of your picture, let's explore how the pixels are actually stored.\n",
        "\n",
        "We'll start with a simpler example: a picture that's just 2 pixels by 2 pixels.\n",
        "\n",
        "![rgbsquare.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAIAAAACAgMAAAAP2OW3AAAADFBMVEUAAAD/AAAA/wAAAP+bwBPcAAAADElEQVR4nGMQYNgAAADkAMEnqOhXAAAAAElFTkSuQmCC)\n",
        "\n",
        "That's super small, so small it probably just looks like dirt on the screen. Here's a blown-up version so you can see each pixel:\n",
        "\n",
        "![rgbsquare_blownup.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUAgMAAADw5/WeAAAADFBMVEUAAAD/AAAA/wAAAP+bwBPcAAAAGElEQVR4nGNgYGANDWUgj1y1av3//+SRAAVdLuEsKjYYAAAAAElFTkSuQmCC)\n",
        "\n",
        "In the top row, the first pixel is black and the second is red. In the bottom row, the first pixel is green and the second is blue.\n",
        "\n",
        "### ✏︎ For you to do\n",
        "\n",
        "Run the code below to see what the entire pixel list looks like. There should only be four pixels in the list, since it's a 2x2 picture.\n"
      ],
      "metadata": {
        "id": "yqtakEwLK6rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lil_pixel_data = get_image_pixels('https://i.imgur.com/YNUJT0Y.png')\n",
        "print(lil_pixel_data)"
      ],
      "metadata": {
        "id": "cNG5lRqiQ2JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pixels list is not just a nested list, it's a 3-dimensional nested list: a list of lists of lists.\n",
        "\n",
        "Here's another way of formatting the list which may make the structure clearer:\n",
        "\n",
        "```\n",
        "[\n",
        "  [ [0, 0, 0],  [255, 0, 0]  ],\n",
        "  [ [0, 255, 0], [0, 0, 255] ]\n",
        "]\n",
        "```\n",
        "\n",
        "The outer list contains lists which represents each row in the picture. Then, each of the row lists contains lists which represent each color channel in the pixel. \n",
        "\n",
        "Each pixel is represented using the  Red-Green-Blue (RGB) scheme for pixels, with a minimum value of 0 and maximum value of 255. The first pixel is black, which is 0 in all channels (devoid of color!). The second pixel in the top row is pure red, so there's a 255 as the first item and the other values are 0. Check out the bottom two pixels and see if the color values align with what you expect.\n",
        "\n",
        "_If you haven't used the RGB color scheme before, play around with [this RGB color picker](https://www.rapidtables.com/web/color/RGB_Color.html) to get a feel for how different amounts of R/G/B make up different colors._\n",
        "\n",
        "The picture you loaded in above is represented the same way in the `pixel_data` list, but it's a much longer list, so it's harder to just look at it and immediately understand each value. \n",
        "\n",
        "### ✏︎ For you to do\n",
        "\n",
        "Run the code snippets below to explore different parts of the `pixel_data` list. Do the values make sense? You're welcome to do some additional exploration beyond what we've suggested."
      ],
      "metadata": {
        "id": "glTgHRltREGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the pixels list\n",
        "len(pixel_data)"
      ],
      "metadata": {
        "id": "Oh25tN92TD_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the first row of the pixels list\n",
        "len(pixel_data[0])"
      ],
      "metadata": {
        "id": "hLWi1OuNTNLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The first pixel in the first row of the pixels list\n",
        "pixel_data[0][0]"
      ],
      "metadata": {
        "id": "NzU5zxjCTaWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Color removal filter\n",
        "\n",
        "In this step, you'll implement three functions to remove an entire color channel from the picture: `remove_red`, `remove_green`, and `remove_blue`. \n",
        "\n",
        "We've started the `remove_red` function for you below. We don't want the function to mutate the original list, so the first line of the function copies the list. You should do all the transformation to that copy, not the original list passed in. The last line of the function then returns that copied list.\n",
        "\n",
        "### ✏︎ For you to do\n",
        "\n",
        "Finish the implementation of `remove_red`, and make sure it works by running it on your image and running the doctests. "
      ],
      "metadata": {
        "id": "C9dfa6uXGKmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_red(pixel_data):\n",
        "  \"\"\" Sets all red channels to 0 in a list of pixels.\n",
        "  >>> remove_red([[[0, 0, 0], [255, 0, 0]], [[0, 255, 0], [0, 0, 255]]])\n",
        "  [[[0, 0, 0], [0, 0, 0]], [[0, 255, 0], [0, 0, 255]]]\n",
        "  \"\"\"\n",
        "  new_pixel_data = copy.deepcopy(pixel_data)\n",
        "  # YOUR CODE HERE\n",
        "  return new_pixel_data\n",
        "\n",
        "# Try it out\n",
        "render_pixels(remove_red(pixel_data))"
      ],
      "metadata": {
        "id": "FI2vVt0pGOO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the doctests\n",
        "doctest.run_docstring_examples(remove_red, globals(), verbose=True, name='remove_red')"
      ],
      "metadata": {
        "id": "crVCScVeOG6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✏︎ For you to do\n",
        "\n",
        "Once you've successfully implemented `remove_red`, write the very similar `remove_green` and `remove_blue` functions below. You'll notice yourself repeating a lot of the same code; feel free to make an additional function to take care of that repetitive code.\n",
        "\n",
        "_If you ever realize you've accidentally modified the original `pixel_data` instead of `new_pixel_data`, just re-run the initial code to reset that list._"
      ],
      "metadata": {
        "id": "nTSpz9dFUHWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def remove_green(pixel_data):\n",
        "  \"\"\" Sets all green channels to 0 in a list of pixels.\n",
        "  >>> remove_green([[[0, 0, 0], [255, 0, 0]], [[0, 255, 0], [0, 0, 255]]])\n",
        "  [[[0, 0, 0], [255, 0, 0]], [[0, 0, 0], [0, 0, 255]]]\n",
        "  \"\"\"\n",
        "  new_pixel_data = copy.deepcopy(pixel_data)\n",
        "  # YOUR CODE HERE\n",
        "  return new_pixel_data\n",
        "\n",
        "def remove_blue(pixel_data):\n",
        "  \"\"\" Sets all blue channels to 0 in a list of pixels.\n",
        "  >>> remove_blue([[[0, 0, 0], [255, 0, 0]], [[0, 255, 0], [0, 0, 255]]])\n",
        "  [[[0, 0, 0], [255, 0, 0]], [[0, 255, 0], [0, 0, 0]]]\n",
        "  \"\"\"\n",
        "  new_pixel_data = copy.deepcopy(pixel_data)\n",
        "  # YOUR CODE HERE\n",
        "  return new_pixel_data\n",
        "  \n",
        "# Try it out\n",
        "render_pixels(remove_green(pixel_data))\n",
        "render_pixels(remove_blue(pixel_data))"
      ],
      "metadata": {
        "id": "bHHLhWXOSc6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tests\n",
        "doctest.run_docstring_examples(remove_green, globals(), verbose=True, name='remove_green')\n",
        "doctest.run_docstring_examples(remove_blue, globals(), verbose=True, name='remove_blue')"
      ],
      "metadata": {
        "id": "oXCb7dsmOEzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Color inversion\n",
        "\n",
        "For the next filter, you'll be inverting each of the color channels, based on the fact that the maximum value of a channel is 255 and the minimum value is 0.\n",
        "\n",
        "For example, for `invert_red`:\n",
        "* If a pixel has a value of 255 for red, the new value should be 0.\n",
        "* If a pixel has a value of 0 for red, the new value should be 255.\n",
        "* If a pixel has a value of 100 for red, the new value should be 155.\n",
        "\n",
        "We've provided the function signatures and doctests for the three inversion functions below. Even though the description above uses if statements, inversion can also be programmed using a bit of arithmetic.\n",
        "\n",
        "Once again, feel free to write a helper function to take care of any redundant code across the three functions.\n",
        "\n",
        "### ✏︎ For you to do\n",
        "\n",
        "Finish the implementation of `invert_red`, `invert_green`, and `invert_blue`, and make sure they work by running them on your image and running the doctests. "
      ],
      "metadata": {
        "id": "P-EYYkTEEJKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def invert_red(pixel_data):\n",
        "  \"\"\" Inverts the red channel in a list of pixels.\n",
        "  >>> invert_red([[[0, 0, 0], [255, 0, 0]], [[0, 255, 0], [0, 0, 255]]])\n",
        "  [[[255, 0, 0], [0, 0, 0]], [[255, 255, 0], [255, 0, 255]]]\n",
        "  >>> invert_red([[[100, 100, 100]]])\n",
        "  [[[155, 100, 100]]]\n",
        "  \"\"\"\n",
        "  new_pixel_data = copy.deepcopy(pixel_data)\n",
        "  # YOUR CODE HERE\n",
        "  return new_pixel_data\n",
        "\n",
        "def invert_green(pixel_data):\n",
        "  \"\"\" Inverts the green channel in a list of pixels.\n",
        "  >>> invert_green([[[0, 0, 0], [255, 0, 0]], [[0, 255, 0], [0, 0, 255]]])\n",
        "  [[[0, 255, 0], [255, 255, 0]], [[0, 0, 0], [0, 255, 255]]]\n",
        "  >>> invert_green([[[100, 100, 100]]])\n",
        "  [[[100, 155, 100]]]\n",
        "  \"\"\"\n",
        "  new_pixel_data = copy.deepcopy(pixel_data)\n",
        "  # YOUR CODE HERE\n",
        "  return new_pixel_data\n",
        "\n",
        "def invert_blue(pixel_data):\n",
        "  \"\"\" Inverts the blue channel in a list of pixels.\n",
        "  >>> invert_blue([[[0, 0, 0], [255, 0, 0]], [[0, 255, 0], [0, 0, 255]]])\n",
        "  [[[0, 0, 255], [255, 0, 255]], [[0, 255, 255], [0, 0, 0]]]\n",
        "  >>> invert_blue([[[100, 100, 100]]])\n",
        "  [[[100, 100, 155]]]\n",
        "  \"\"\"\n",
        "  new_pixel_data = copy.deepcopy(pixel_data)\n",
        "  # YOUR CODE HERE\n",
        "  return new_pixel_data\n",
        "\n",
        "# Try it out\n",
        "render_pixels(invert_red(pixel_data))\n",
        "render_pixels(invert_green(pixel_data))\n",
        "render_pixels(invert_blue(pixel_data))"
      ],
      "metadata": {
        "id": "lMOwspypBogG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tests\n",
        "doctest.run_docstring_examples(invert_red, globals(), verbose=True, name='invert_red')\n",
        "doctest.run_docstring_examples(invert_green, globals(), verbose=True, name='invert_green')\n",
        "doctest.run_docstring_examples(invert_blue, globals(), verbose=True, name='invert_blue')"
      ],
      "metadata": {
        "id": "SXzUv1CCN5tX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Total inversion\n",
        "\n",
        "What would it look like if we inverted all the channels in an image? In a black&white image, that would mean all the black areas (0, 0, 0) would become white (255, 255, 255).\n",
        "\n",
        "### ✏︎ For you to do\n",
        "\n",
        "If you've implemented the three functions above correctly, you should be able to just run the code below and see what total inversion looks like on your image. You don't need to write any code yourself, just run it and see what happens!"
      ],
      "metadata": {
        "id": "MZCgG9WaZVfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "render_pixels(invert_blue(invert_green(invert_red(pixel_data))))\n"
      ],
      "metadata": {
        "id": "n87fmHxfZ0AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grayscale\n",
        "\n",
        "Woo, that was wild! Let's tone things down a bit with a grayscale filter. In a grayscale image, all the pixels are somewhere in the spectrum between black and white - from (0, 0, 0) to (255, 255, 255). That means the red, green, and blue channels are always equal in value. As soon as one channel is higher than another, we start to see that color instead.\n",
        "\n",
        "So, to convert a pixel into a grayscale pixel, the standard approach is to take the average of of the red, green, and blue values (by summing them up and then dividing by three). Note that RGB values should only be integers, not floats, so you may need to do some rounding.\n",
        "\n",
        "### ✏︎ For you to do\n",
        "\n",
        "Finish the implementation of `grayscale` according to the approach described above, and make sure it works by running it on your image and running the doctests.\n"
      ],
      "metadata": {
        "id": "PlUGXSkPEwMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grayscale(pixel_data):\n",
        "  \"\"\" Converts all the pixels in a pixel list to grayscale.\n",
        "  >>> grayscale([[[0, 0, 0], [255, 0, 0]], [[0, 255, 0], [0, 0, 255]]])\n",
        "  [[[0, 0, 0], [85, 85, 85]], [[85, 85, 85], [85, 85, 85]]]\n",
        "  \"\"\"\n",
        "  new_pixel_data = copy.deepcopy(pixel_data)\n",
        "  # YOUR CODE HERE\n",
        "  return new_pixel_data\n",
        "\n",
        "# Try it out\n",
        "render_pixels(grayscale(pixel_data))"
      ],
      "metadata": {
        "id": "znuVMwGEE94u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tests\n",
        "doctest.run_docstring_examples(grayscale, globals(), verbose=True, name='grayscale')"
      ],
      "metadata": {
        "id": "cE3s8AH3OQnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flipping 🐬\n",
        "\n",
        "In this step, you'll write two functions that can flip the picture, one to flip it horizontally and the other to flip it vertically.\n",
        "\n",
        "These functions are a bit different than the previous ones that operated only on a pixel at a time. Instead, they'll need to actually change the position of each pixels inside the list (while keeping the actual pixel the same).\n",
        "\n",
        "For example, when flipping horizontally, the very first pixel in a row will become the very last pixel instead. You may need to use a very different approach for this code, especially for flipping vertically.\n",
        "\n",
        "For additional guidance, check out this [short video](https://www.youtube.com/watch?v=xY-ADtNHF5A).\n",
        "\n",
        "### ✏︎ For you to do\n",
        "\n",
        "Finish the implementation of `flip_horizontal` and `flip_vertical`, and make sure they work by running them on your image and running the doctests. "
      ],
      "metadata": {
        "id": "KmbEAlGYHEKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flip_horizontal(pixel_data):\n",
        "  \"\"\" Flips the pixels in the list so that the left-most become the right-most.\n",
        "  >>> flip_horizontal([[[0, 0, 0], [255, 0, 0]], [[0, 255, 0], [0, 0, 255]]])\n",
        "  [[[255, 0, 0], [0, 0, 0]], [[0, 0, 255], [0, 255, 0]]]\n",
        "  \"\"\"\n",
        "  new_pixel_data = copy.deepcopy(pixel_data)\n",
        "  # YOUR CODE HERE\n",
        "  return new_pixel_data\n",
        "\n",
        "def flip_vertical(pixel_data):\n",
        "  \"\"\" Flips the pixels in the list so that the top-most become the bottom-most.\n",
        "  >>> flip_vertical([[[0, 0, 0], [255, 0, 0]], [[0, 255, 0], [0, 0, 255]]])\n",
        "  [[[0, 255, 0], [0, 0, 255]], [[0, 0, 0], [255, 0, 0]]]\n",
        "  \"\"\"\n",
        "  new_pixel_data = copy.deepcopy(pixel_data)\n",
        "  # YOUR CODE HERE\n",
        "  return new_pixel_data\n",
        "\n",
        "# Try it out\n",
        "render_pixels(flip_horizontal(pixel_data))\n",
        "render_pixels(flip_vertical(pixel_data))"
      ],
      "metadata": {
        "id": "uHsDa6q8HIX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tests\n",
        "doctest.run_docstring_examples(flip_horizontal, globals(), verbose=True, name='flip_horizontal')\n",
        "doctest.run_docstring_examples(flip_vertical, globals(), verbose=True, name='flip_vertical')"
      ],
      "metadata": {
        "id": "Nfv6CQMin0Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All done!\n",
        "\n",
        "🎉 Congratulations! You've finished the project and are ready to unleash your image manipulation on the world. If you enjoyed that, check out the extension ideas below. See you next week!\n",
        "\n"
      ],
      "metadata": {
        "id": "7zd9lRXinEvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extensions\n",
        "\n",
        "Here are some ideas for additional filters to implement:\n",
        "\n",
        "\n",
        "* **Horizontal blur**: There are many blurring algorithms. One of the simpler approach starts by replacing the red values of three adjacent pixels with their average, then doing the same with the green and blue values. \n",
        "* **Vertical blur**: Same as above, but computed vertically instead. The code will be more complicated since you'll need to keep track of indices (similar to the complexity of flipping vertically).\n",
        "* **Extreme contrast**: Change each color channel to either 255 or 0, based on which value it's closest to.\n",
        "* **Stripes**: For any of the filters already implemented, make a function that only applies it to stripes of the image (i.e. alternating stripes of 20 pixels).\n",
        "\n"
      ],
      "metadata": {
        "id": "1RzF9rTznXXp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attribution\n",
        "\n",
        "Inspiration for this project comes from the [PPM Image Editor project](http://nifty.stanford.edu/2012/guerin-image-editor/) by Joshua Guerin T and Debby Keen, as presented at SIGCSE Nifty Projects 2012."
      ],
      "metadata": {
        "id": "Nw0H4le4pJG2"
      }
    }
  ]
}